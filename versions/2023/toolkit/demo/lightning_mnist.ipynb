{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Lightning for MNIST\n",
    "\n",
    "Lighting to easily train and test a model on MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install lightning torchmetrics --upgrade\n",
    "! pip install torch torchvision --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataModule for MNIST\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import lightning as L\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# create an MNIST datamodule\n",
    "\n",
    "class MNISTDataModule(L.LightningDataModule):\n",
    "    def __init__(self, batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_data(self):\n",
    "        torchvision.datasets.MNIST(root=\"./data\", download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.mnist_train = torchvision.datasets.MNIST(\n",
    "                root=\"./data\", train=True, download=True, transform=transforms.ToTensor()\n",
    "            )\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = torchvision.datasets.MNIST(\n",
    "                root=\"./data\", train=False,download=True, transform=transforms.ToTensor()\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.mnist_train, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.mnist_test, batch_size=self.batch_size, shuffle=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-layer CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(800, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.features(x)\n",
    "        y = torch.flatten(y, 1)\n",
    "        y = self.classifier(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightningModule for MNIST\n",
    "\n",
    "Notice this module uses the sample `CNN()` model defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a pytorch lightning model\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "class LitModel(L.LightningModule):\n",
    "    def __init__(self, model=CNN()):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.avg_acc = []\n",
    "        self.avg_loss = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        lr = self.trainer.optimizers[0].param_groups[0][\"lr\"]\n",
    "        self.log(\"learning_rate\", lr, on_step=False, on_epoch=True, prog_bar=True, logger=True)    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y)\n",
    "        self.avg_acc.append(acc)\n",
    "        self.avg_loss.append(loss)\n",
    "        return loss, acc\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        loss = torch.stack(self.avg_loss).mean()\n",
    "        acc = torch.stack(self.avg_acc).mean()\n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"test_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.avg_acc = []\n",
    "        self.avg_loss = []\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing the Model\n",
    "\n",
    "Note how we use the `Trainer` class to train and test the model. Also, note the selection of accelerator and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for 10 epochs\n",
    "\n",
    "dm = MNISTDataModule()\n",
    "model = LitModel()\n",
    "trainer = L.Trainer(max_epochs=10, accelerator=\"gpu\", devices=[0], precision=16)\n",
    "trainer.fit(model, dm)\n",
    "trainer.test(model, dm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mspeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
